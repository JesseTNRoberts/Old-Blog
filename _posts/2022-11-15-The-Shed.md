## Too many incidentals

Today had many popup tasks. That gives me an excuse. But I'm still going to try to get some progress by honing my question and trying to convince myself that author ID via language model is a good idea.

### The shed

We're having a shed put in the backyard today. I had to prep the site yesterday in spare time. Now I'm waiting on the install crew to call me and let me know that they are on the way. So, overseeing that is the background task for the morning. Hopefully, I'll still be able to get some research done between the shed, faculty meeting, and research group meeting this afternoon. 

### The gas

Also, it seems that the gas crew will be at the house on Friday to install the gas stove and run the line out to the HVAC unit. So, I'll need to go get the black iron pipe between now and then. 

I have already sized the pipe and the pressure. So, I'll need to cobble together a parts list (I'll put it here) and go to the hardware store.

### Feedback on singoffs

The capstone teams are using Github as a means of submitting detail designs. I have checked in with the githubs pull requests and checked the experimental results.

## To the point

### Adapting Language Models for Non-Parallel Author-Stylized Rewriting - 2020

In this paper the authors report on a method to adapt GPT-2 to produce stylistic similarities to specific authors. They compare their work to other similar methods to produce stylistic variations specific to known author corpi (fancy language that). 

#### Question - Does this suggest that language models internalize author specific information?

Not necessarily. It suggests that they internalize all authors. Then the network can be biased toward a specific author's style. It does not necessarily suggest that the distance between text in a specific style is far in latent space from another style. 

This suggests that not only is author ID via language model an open question, but that it may be an open question whether or not the pretrained representation has sufficient variance given a difference in style to adequately recognize a specific author.

### Parks and Rec

Vote Bobby Newport.

### Locating and Editing Factual Associations in GPT - 2021

A friend recommended this paper because it involves editing knowledge stored in language models. The general idea is to attribute blaim for a specific piece of factual information to a specific MLP layer in the output stages of a transformer network decoder. They show that they can edit the weights of the subset of the MLP to change a fact.

From the paper:
> Our evaluation reveals that, even when the a modelâ€™s stored factual association is changed successfully, the model will guess plausible new facts that have no basis in evidence and that are likely to be false.

Interestingly, this suggests that the model has learned a hierarchical strategy. It selects an appropriate part of speech even when the weights no longer select the intended concept. So, it selected the right branch of the tree but failed to find the right leaf. 

Another point to be made is that the edit to the network so far can't add knowledge to the network. Rather, it simply deassociates a key with a value.

So, if a person were to want to, I don't know, add additional tokens representing new, slower moving signals into the network, this would not allow you to do so. 

##### Relevant Takeaway 

Not all weights need to be edited to bias a network in a manner to select a specific word (or deselect it?) from a particular part of speech. Rather, a small (relatively) number of weights can be edited to bias the network. So, the output dimensionality of the interneuron network might be able to be somewhat small and still accomplish stylistic shift. 





