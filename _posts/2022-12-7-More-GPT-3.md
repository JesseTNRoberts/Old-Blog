## Experimental Questions

- Do transformer based PLMs possess representations which are sufficient for recognition of rhetorical structures?

- What is the optimal set of exemplars for few shot teaching for GPT-2 based system?
- What is the optimal set of exemplars for teaching BERT?
- Which of these perform best as exemplars for GPT-3 (assuming each set is unique). 

- Can language models expand expand the compact rhetorical meaning represented in structures like chiasma? (Good question but may be addressed in a follow up paper)

## Experimental Design

The easy experiment is to use exemplars for few shot teaching the language models. Then use the language model to classify the structures by presenting patterned cloze test questions to the model.

I am not yet certain how to identify the optimal, minimal exemplar subset beyond brute force. 

It is also not clear how one should ask a language model to expand the meaning of a rhetorical structure. This is a good idea. But I'm not sure that I want to address this in the first paper. 

## Well that went badly

So, the first step to the experimental design above was to get some rudimentary GPT-2 based method working to classify chiasma correctly. However, immediately that proved challenging. Actually, it proved to be a total flop. 

And by total flop I mean, it was randomly generating chiasm and not a chiasm. 

Ok. Why?


## Maybe it was a fluke?

In the original experiment that I ran a few days past, I gave 2 unseen examples each of which was a binary classification task. There is a 25% chance that GPT-3 got lucky. That is it may have essentially generated two random binary values and happened to get them both correct. So, I will redo the experiment with expanded testing. 

Training: 
> 
> ban with permit reservation to a permit with ban: chiasm
> 
> citizen consumers rather than consumer citizens: chiasm
> 
> Independence is language and language is independence: chiasm
> 
> rules and laws and that laws and rules: nothing 
> 
> Directive is inapplicable in Denmark , or Denmark is required by the Directive: nothing
> 

Testing:
> 
> would be appropriate if the European political parties took part in national elections , rather than having national political parties take part in European elections: Chiasm
> 
> entrenches a situation in which protected companies can take over unprotected ones , yet unprotected companies cannot take over protected ones: chiasm
> 
> is much better to bring work to people that to take people to work: chiasm
> 
> bringing about famine , famine brings about wars , and wars are bringing about disease , against: nothing
> 
> man is not made for the law , but rather law is made for man: chiasm
> 
> the question of our overall policy on human rights and the relationship between human rights and foreign policy:  nothing


#### Code

````
import os
import openai

openai.api_key = os.getenv("OPENAI_API_KEY")

restart_sequence = "\n"

response = openai.Completion.create(
  model="text-davinci-003",
  prompt="ban with permit reservation to a permit with ban: chiasm\n\ncitizen consumers rather than consumer citizens: chiasm\n\nIndependence is language and language is independence: chiasm\n\nrules and laws and that laws and rules: nothing \n\nDirective is inapplicable in Denmark , or Denmark is required by the Directive: nothing\n\nwould be appropriate if the European political parties took part in national elections , rather than having national political parties take part in European elections: Chiasm\n\nentrenches a situation in which protected companies can take over unprotected ones , yet unprotected companies cannot take over protected ones: chiasm\n\nis much better to bring work to people that to take people to work: chiasm\n\nbringing about famine , famine brings about wars , and wars are bringing about disease , against: nothing\n\nman is not made for the law , but rather law is made for man: chiasm\n\nthe question of our overall policy on human rights and the relationship between human rights and foreign policy:  nothing",
  temperature=0,
  max_tokens=6,
  top_p=1,
  frequency_penalty=0,
  presence_penalty=0,
  stop=["\n"]
)
````

### Fairly Conclusive

Ok. Now it is all but proved that GPT-3 can accurately classify text as containing or not containing chiasmus. The probability that the above results could be generated through a random guess is 1.5%. 


