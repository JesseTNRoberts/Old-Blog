# How to identify near optimal prompts for zero shot learning

In some situations is ideal to utilize a large language model without fine tuning the model. Typically, this is because the time required to tine tune is far greater than required to inference an existing model with an appropriate pattern and prompt. However, designing a prompt can be very time consuming. Further, it can be costly as large models are under the control of proprietary groups which may not distribute the model. 

The question is then, how can a prompt be developed on a less costly model which can then be used on the state of the art model. 

