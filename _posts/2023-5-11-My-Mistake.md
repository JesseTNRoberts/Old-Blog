## My Mistake

So, as it turns out, my construction for the Turing completeness of decoder-only transformer models is a bit off. However, it is readily fixable. The mistake was that I failed to realize what the output of the transformer would be. 

The output of a decoder-only transformer is the output from the neural network in the last layer of the transformer given only the last vector in the sequence of vectors generated by self-attention. I had erroneously thought the neural network was a massively connected network which was able to take in all vectors in the sequence at once. However, it makes since that this network would be difficult to implement and is unnecessary (not to mention the exponential growth in computational cost it would induce). Most importantly, that's not how the network is built. 

So, now that I realize this, the new proof construction is simpler. The model dimension is going to be the 2 times the embedding dimension plus two elements, one for the current time step and one for if the stop token has been seen. Then, one attention head will attend to the input while the other attends to the hidden state (last output) - this is true when the last vector is used to generate the last query. These attention heads are then concatenated. The order of concatenation is important. The last output has to be in the first part of the vector. Technically, the attention head attenting to the next input also has a 2 times multiplier also. This way, when the residual connection is applied both the input and the hidden state have a two times multiplier. Normalization returns them to the proper value. 


It might be possible to do this with a single head.
